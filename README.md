# Econometrics-  LPM: Подгонка, интерпретация коэффициентов, t-тест

Цель: Оценить модель, понять влияние факторов на вероятность, проверить значимость каждого коэффициента.

python
import pandas as pd
import statsmodels.formula.api as smf

# Загрузка данных
df = pd.read_csv('data.csv')
# Спецификация
mod_lpm = smf.ols(formula='approve ~ age + education + income', data=df)
# Оценка с робастными ошибками (ВСЕГДА для LPM!)
res = mod_lpm.fit(cov_type='HC3')
print(res.summary(slim=True))
Ключевой вывод из summary:

text
                 coef    std err          z      P>|z|
Intercept      0.2000      0.050      4.000      0.000
age           -0.0050      0.002     -2.500      0.012
education      0.0400      0.010      4.000      0.000
income         0.0002      0.000      1.000      0.317
Интерпретация:

Для значимых коэффициентов (p-value < 0.05):

education: "При увеличении образования на 1 год, вероятность одобрения (approve=1) возрастает в среднем на 4 процентных пункта (п.п.), при условии, что другие факторы (возраст, доход) остаются неизменными. Эффект статистически значим на уровне 5% (p-value=0.000)."
age: "С увеличением возраста на 1 год вероятность одобрения снижается на 0.5 п.п., при прочих равных (p-value=0.012 < 0.05)."
Для незначимого коэффициента (p-value >= 0.05):

income: "Коэффициент при доходе статистически незначим на уровне 5% (p-value=0.317). Это означает, что при контроле возраста и образования мы не обнаружили значимого влияния дохода на вероятность одобрения."
Что такое t-тест (здесь z-тест из-за HC3)?
Это проверка H₀: коэффициент = 0 против H₁: коэффициент ≠ 0. P>|z| — это p-value для этого теста. Решение: если p-value < α → отвергаем H₀, коэффициент значим.

2. LPM: F-тест, прогнозирование и интерпретация прогноза

А) F-тест на значимость регрессии в целом

python
# F-тест уже есть в summary: Prob (F-statistic)
print(f"F-statistic p-value: {res.f_pvalue:.4f}")

# Или тест совместной значимости группы переменных (например, age и income)
ftest = res.f_test('age=income=0')
print(ftest)
Интерпретация:

Если Prob (F-statistic) < 0.05: "Модель в целом статистически значима на уровне 5% (p-value=...). Это означает, что хотя бы один из включенных регрессоров значимо влияет на зависимую переменную."
Если p-value > 0.05: "Модель в целом статистически незначима на уровне 5%. Нет доказательств, что предложенный набор переменных совместно объясняет вариацию вероятности."
Б) Прогнозирование

python
# Прогноз для новых данных (или для первых 5 наблюдений из выборки)
new_data = pd.DataFrame({'age': [30, 40], 'education': [16, 12], 'income': [50000, 30000]})
predicted_probs = res.predict(new_data)
print(predicted_probs)
# Output: array([0.745, 0.512])
Интерпретация прогноза:
"Для 30-летнего заявителя с 16 годами образования и доходом 50,000, предсказанная вероятность одобрения кредита составляет 74.5%."
"Для 40-летнего с 12 годами образования и доходом 30,000, предсказанная вероятность составляет 51.2%."

Важно: В LPM прогноз может выйти за пределы [0;1] (это её недостаток).

3. Logit/Probit: Подгонка, интерпретация коэффициентов, z-тест

python
# Logit модель
mod_logit = smf.logit(formula='approve ~ age + education + income', data=df)
res_logit = mod_logit.fit()
print(res_logit.summary())

# Probit модель (меняется только функция)
# mod_probit = smf.probit(formula='...', data=df)
Ключевой вывод:

text
                 coef    std err          z      P>|z|
Intercept     -2.5000      0.600     -4.167      0.000
age           -0.0800      0.030     -2.667      0.008
education      0.4000      0.100      4.000      0.000
income         0.0030      0.002      1.500      0.134
Интерпретация (сложнее, чем в LPM!):

Знак коэффициента: Показывает направление влияния.

education (0.400) > 0 → больше образования → выше вероятность одобрения.
age (-0.080) < 0 → больше возраст → ниже вероятность одобрения.
z-тест (аналогичен t-тесту): P>|z| — p-value для теста H₀: коэффициент=0.

education, age: p-value < 0.05 → коэффициенты значимы.
income: p-value=0.134 > 0.05 → незначим.
Содержательная интерпретация через предельные эффекты (или отношение шансов для Logit):

Предельный эффект (в среднем): Показывает, на сколько п.п. изменится вероятность при изменении предиктора на 1 единицу. Рассчитывается отдельно:
python
marginal_effects = res_logit.get_margeff()
print(marginal_effects.summary())
Интерпретация: "Средний предельный эффект переменной education составляет 0.062. Это означает, что при увеличении образования на 1 год, вероятность одобрения в среднем возрастает на 6.2 процентных пункта, при условии неизменности других факторов."
4. Logit/Probit: Значимость регрессии, совместная значимость (LR-тест, W-тест)

А) Значимость всей модели (аналог F-теста)

Смотрим на LLR p-value (Log-Likelihood Ratio test p-value) в начале summary().
Интерпретация: "P-value LLR-теста < 0.05, следовательно, модель в целом статистически значима."

Б) LR-тест на совместную значимость группы переменных

python
# Оцениваем полную (u) и ограниченную (r) модели на ОДНОМ наборе данных
df_clean = df[['approve','age','education','income']].dropna()

mod_u = smf.logit('approve ~ age + education + income', df_clean).fit()
mod_r = smf.logit('approve ~ education', df_clean).fit() # без age и income

# LR статистика = 2*(llf_u - llf_r)
lr_stat = 2*(mod_u.llf - mod_r.llf)
from scipy.stats import chi2
p_value = chi2.sf(lr_stat, df=2) # df = кол-во опущенных переменных (age, income -> 2)
print(f"LR stat: {lr_stat:.3f}, p-value: {p_value:.4f}")
Интерпретация:
"Если p-value < 0.05: На уровне значимости 5% отвергаем H₀ о том, что коэффициенты при age и income одновременно равны нулю. Переменные age и income являются совместно статистически значимыми."

В) Тест Вальда (W-тест)

python
# Проверяем ту же гипотезу
wald_test = mod_u.wald_test('age=income=0')
print(wald_test)
Интерпретация та же: Смотрим на p-value из результата теста.

5. Контрольная №1: Общий алгоритм

Для задачи "подгонка и тестирование" действуйте по шагам:

Определить тип модели:

Если сказано "LPM" или явно нужна линейная вероятность → smf.ols с cov_type='HC3'.
Если сказано "логит" → smf.logit.
Если "пробит" → smf.probit.
Оценить модель:

python
mod = smf.ols/logit/probit(formula='Y ~ X1 + X2 + ...', data=df)
res = mod.fit(cov_type='HC3') # для LPM
# или res = mod.fit() # для logit/probit
print(res.summary(slim=True))
Дать общую характеристику:

Для LPM: "Модель в целом значима/незначима (p-value F-теста = ...)."
Для Logit/Probit: "Модель в целом значима/незначима (LLR p-value = ...)."
Интерпретировать значимые коэффициенты:

LPM: "Коэффициент при X1 равен b1. Это означает, что при увеличении X1 на 1 единицу, вероятность Y=1 изменяется на b1*100 процентных пунктов, при прочих равных (p-value=...)."
Logit/Probit: "Коэффициент при X1 равен b1 и значим (p-value=...). Его положительный знак указывает на положительное влияние на вероятность Y=1. Для количественной интерпретации следует рассчитать предельные эффекты."
Выполнить требуемые тесты (F, LR, Вальда):

Использовать код из соответствующих разделов выше.
Четко сформулировать гипотезы (H₀ и H₁).
Привести тестовую статистику и p-value.
Сделать вывод, указав уровень значимости (α): "На уровне значимости 5% мы отвергаем/не отвергаем H₀, потому что p-value = ... </>= 0.05."
Сделать прогноз (если просят):

Использовать res.predict().
Интерпретировать результат как вероятность.
Главный совет: В интерпретации всегда используйте фразы:

"при условии, что другие факторы остаются неизменными"
"статистически значим на уровне ... (p-value=...)"
"вероятность изменяется на ... процентных пунктов (для LPM и предельных эффектов)"
